{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "#### Case Study: Spam Detection\n",
    "A lot of people lost money because of spam emails. Business lost countless of capital because of spam fraud. With the rate of increase of technology, criminals become smart and it is only reasonable that business match or even be better in this ever increasing crime when it comes to spam detection. In this case, I was provided with the data to detect whether the mail I recieved is either a spam or not. It is a basic logitic problem but it comes with the cost that should I predict that a mail is a spam when infact it's not, the company tends to lose R80 000 and if the mail is not a spam while infact it is, the company lose R1000.\n",
    "\n",
    "#### Logistic Regression intuition\n",
    "In statistics, the Logistic Regression model is a widely used statistical model which is primarily used for classification purposes. It means that given a set of observations, Logistic Regression algorithm helps us to classify these observations into two or more discrete classes. So, the target variable is discrete in nature.\n",
    "\n",
    "####  Assumptions of Logistic Regression\n",
    "\n",
    "The Logistic Regression model requires several key assumptions. These are as follows:-\n",
    "\n",
    "* Logistic Regression model requires the dependent variable to be binary, multinomial or ordinal in nature.\n",
    "\n",
    "* It requires the observations to be independent of each other. So, the observations should not come from repeated measurements.\n",
    "\n",
    "* Logistic Regression algorithm requires little or no multicollinearity among the independent variables. It means that the independent variables should not be too highly correlated with each other.\n",
    "\n",
    "* Logistic Regression model assumes linearity of independent variables and log odds.\n",
    "\n",
    "* The success of Logistic Regression model depends on the sample sizes. Typically, it requires a large sample size to achieve the high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    " \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the home directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(''):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "data = 'CaseStudyData.csv'\n",
    "\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will explore the data to gain insights about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 600 instances and 10 variables in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TargetVariable</th>\n",
       "      <th>Variable1</th>\n",
       "      <th>Variable2</th>\n",
       "      <th>Variable3</th>\n",
       "      <th>Variable4</th>\n",
       "      <th>Variable5</th>\n",
       "      <th>Variable6</th>\n",
       "      <th>Variable7</th>\n",
       "      <th>Variable8</th>\n",
       "      <th>Variable9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.357542</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>4.606326</td>\n",
       "      <td>0</td>\n",
       "      <td>square</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000362</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>10.824921</td>\n",
       "      <td>0</td>\n",
       "      <td>round</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000029</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3</td>\n",
       "      <td>69.55</td>\n",
       "      <td>green</td>\n",
       "      <td>5.861325</td>\n",
       "      <td>8</td>\n",
       "      <td>square</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.020183</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>10.896444</td>\n",
       "      <td>0</td>\n",
       "      <td>triangle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.952665</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.50</td>\n",
       "      <td>blue</td>\n",
       "      <td>9.159679</td>\n",
       "      <td>0</td>\n",
       "      <td>triangle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TargetVariable  Variable1  Variable2  Variable3 Variable4 Variable5  \\\n",
       "0               1   2.357542       29.0          2    10.50      green   \n",
       "1               1   2.000362       50.0          2    10.50      green   \n",
       "2               0   2.000029       34.0          3    69.55      green   \n",
       "3               1   2.020183       50.0          2    10.50      green   \n",
       "4               0   2.952665       45.0          1    35.50       blue   \n",
       "\n",
       "   Variable6  Variable7 Variable8  Variable9  \n",
       "0   4.606326          0    square          0  \n",
       "1  10.824921          0     round          0  \n",
       "2   5.861325          8    square          2  \n",
       "3  10.896444          0  triangle          0  \n",
       "4   9.159679          0  triangle          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TargetVariable', 'Variable1', 'Variable2', 'Variable3', 'Variable4',\n",
       "       'Variable5', 'Variable6', 'Variable7', 'Variable8', 'Variable9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df.columns\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 10 columns):\n",
      "TargetVariable    600 non-null int64\n",
      "Variable1         600 non-null float64\n",
      "Variable2         600 non-null float64\n",
      "Variable3         600 non-null int64\n",
      "Variable4         600 non-null object\n",
      "Variable5         600 non-null object\n",
      "Variable6         600 non-null float64\n",
      "Variable7         600 non-null int64\n",
      "Variable8         600 non-null object\n",
      "Variable9         600 non-null int64\n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# view summary of dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of variables\n",
    "\n",
    "In this section, I segregate the dataset into categorical and numerical variables. There are a mixture of categorical and numerical variables in the dataset. Categorical variables have data type object. Numerical variables have data type float64.\n",
    "\n",
    "First of all, I will find categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 categorical variables\n",
      "\n",
      "The categorical variables are : ['Variable4', 'Variable5', 'Variable8']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable4</th>\n",
       "      <th>Variable5</th>\n",
       "      <th>Variable8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>round</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.55</td>\n",
       "      <td>green</td>\n",
       "      <td>square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.50</td>\n",
       "      <td>green</td>\n",
       "      <td>triangle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.50</td>\n",
       "      <td>blue</td>\n",
       "      <td>triangle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable4 Variable5 Variable8\n",
       "0    10.50      green    square\n",
       "1    10.50      green     round\n",
       "2    69.55      green    square\n",
       "3    10.50      green  triangle\n",
       "4    35.50       blue  triangle"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the categorical variables\n",
    "\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of categorical variables\n",
    "There is a date variable. It is denoted by Date column. <br>\n",
    "There are 6 categorical variables. These are given by Variable4, Variable5, WindDir9am, and Variable8.<br>\n",
    "There is one binary categorical variable Variable5.<br>\n",
    "Variable4 just need to be converted to numerical<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore problems within categorical variables\n",
    "\n",
    "First, I will explore the categorical variables.\n",
    "\n",
    "Missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable4    0\n",
       "Variable5    0\n",
       "Variable8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables\n",
    "\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values in the categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency counts of categorical variables\n",
    "Now, I will check the frequency counts of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.05       35\n",
      " 26.00      26\n",
      " 13.00      26\n",
      " 7.75       26\n",
      " 7.90       23\n",
      " 7.23       18\n",
      " 10.50      17\n",
      " 7.25       12\n",
      " 7.93       12\n",
      " 26.55      11\n",
      " 7.78        9\n",
      " -           9\n",
      " 8.66        9\n",
      " 7.85        8\n",
      " 9.50        6\n",
      " 7.05        5\n",
      " 21.00       5\n",
      " 14.50       5\n",
      " 7.88        5\n",
      " 7.80        5\n",
      " 27.72       5\n",
      " 24.15       5\n",
      " 15.50       5\n",
      " 14.45       4\n",
      " 69.55       4\n",
      " 31.39       4\n",
      " 26.25       4\n",
      " 31.28       4\n",
      " 52.00       4\n",
      " 15.85       4\n",
      "            ..\n",
      " 93.50       1\n",
      " 20.58       1\n",
      " 47.10       1\n",
      " 7.83        1\n",
      " 30.00       1\n",
      " 22.53       1\n",
      " 8.03        1\n",
      " 6.86        1\n",
      " 9.22        1\n",
      " 221.78      1\n",
      " 7.79        1\n",
      " 16.00       1\n",
      " 22.03       1\n",
      " 23.00       1\n",
      " 6.75        1\n",
      " 7.31        1\n",
      " 12.00       1\n",
      " 76.73       1\n",
      " 164.87      1\n",
      " 15.74       1\n",
      " 24.00       1\n",
      " 7.55        1\n",
      " 6.98        1\n",
      " 50.00       1\n",
      " 14.00       1\n",
      " 69.30       1\n",
      " 77.96       1\n",
      " 32.50       1\n",
      " 26.28       1\n",
      " 26.39       1\n",
      "Name: Variable4, Length: 206, dtype: int64\n",
      "blue     377\n",
      "green    223\n",
      "Name: Variable5, dtype: int64\n",
      "square      237\n",
      "round       183\n",
      "triangle    180\n",
      "Name: Variable8, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# view frequency of categorical variables\n",
    "\n",
    "for var in categorical: \n",
    "    \n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.05       0.058333\n",
      " 26.00      0.043333\n",
      " 13.00      0.043333\n",
      " 7.75       0.043333\n",
      " 7.90       0.038333\n",
      " 7.23       0.030000\n",
      " 10.50      0.028333\n",
      " 7.25       0.020000\n",
      " 7.93       0.020000\n",
      " 26.55      0.018333\n",
      " 7.78       0.015000\n",
      " -          0.015000\n",
      " 8.66       0.015000\n",
      " 7.85       0.013333\n",
      " 9.50       0.010000\n",
      " 7.05       0.008333\n",
      " 21.00      0.008333\n",
      " 14.50      0.008333\n",
      " 7.88       0.008333\n",
      " 7.80       0.008333\n",
      " 27.72      0.008333\n",
      " 24.15      0.008333\n",
      " 15.50      0.008333\n",
      " 14.45      0.006667\n",
      " 69.55      0.006667\n",
      " 31.39      0.006667\n",
      " 26.25      0.006667\n",
      " 31.28      0.006667\n",
      " 52.00      0.006667\n",
      " 15.85      0.006667\n",
      "              ...   \n",
      " 93.50      0.001667\n",
      " 20.58      0.001667\n",
      " 47.10      0.001667\n",
      " 7.83       0.001667\n",
      " 30.00      0.001667\n",
      " 22.53      0.001667\n",
      " 8.03       0.001667\n",
      " 6.86       0.001667\n",
      " 9.22       0.001667\n",
      " 221.78     0.001667\n",
      " 7.79       0.001667\n",
      " 16.00      0.001667\n",
      " 22.03      0.001667\n",
      " 23.00      0.001667\n",
      " 6.75       0.001667\n",
      " 7.31       0.001667\n",
      " 12.00      0.001667\n",
      " 76.73      0.001667\n",
      " 164.87     0.001667\n",
      " 15.74      0.001667\n",
      " 24.00      0.001667\n",
      " 7.55       0.001667\n",
      " 6.98       0.001667\n",
      " 50.00      0.001667\n",
      " 14.00      0.001667\n",
      " 69.30      0.001667\n",
      " 77.96      0.001667\n",
      " 32.50      0.001667\n",
      " 26.28      0.001667\n",
      " 26.39      0.001667\n",
      "Name: Variable4, Length: 206, dtype: float64\n",
      "blue     0.628333\n",
      "green    0.371667\n",
      "Name: Variable5, dtype: float64\n",
      "square      0.395\n",
      "round       0.305\n",
      "triangle    0.300\n",
      "Name: Variable8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# view frequency distribution of categorical variables\n",
    "\n",
    "for var in categorical: \n",
    "    \n",
    "    print(df[var].value_counts()/np.float(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of labels: cardinality\n",
    "The number of labels within a categorical variable is known as cardinality. A high number of labels within a variable is known as high cardinality. High cardinality may pose some serious problems in the machine learning model. So, I will check for high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable4  contains  206  labels\n",
      "Variable5  contains  2  labels\n",
      "Variable8  contains  3  labels\n"
     ]
    }
   ],
   "source": [
    "# check for cardinality in categorical variables\n",
    "\n",
    "for var in categorical:\n",
    "    \n",
    "    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a Veriable4 variable which needs to be preprocessed. I will do preprocessing in the following section.\n",
    "\n",
    "All the other variables contain relatively smaller number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering of Veriable4 Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Variable4'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data type of Variable4 variable is object. I will convert it to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Variable4'] = pd.to_numeric(df['Variable4'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Variable4'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 10 columns):\n",
      "TargetVariable    600 non-null int64\n",
      "Variable1         600 non-null float64\n",
      "Variable2         600 non-null float64\n",
      "Variable3         600 non-null int64\n",
      "Variable4         591 non-null float64\n",
      "Variable5         600 non-null object\n",
      "Variable6         600 non-null float64\n",
      "Variable7         600 non-null int64\n",
      "Variable8         600 non-null object\n",
      "Variable9         600 non-null int64\n",
      "dtypes: float64(4), int64(4), object(2)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# again view the summary of dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Categorical Variables\n",
    "Now, I will explore the categorical variables one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables\n",
      "\n",
      "The categorical variables are : ['Variable5', 'Variable8']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :', categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 2 categorical variables in the dataset. The Variable4 variable has been converted to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable5    0\n",
       "Variable8    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values in categorical variables \n",
    "\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will explore variable5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable5 contains 2 labels\n"
     ]
    }
   ],
   "source": [
    "# print number of labels in Location variable\n",
    "\n",
    "print('Variable5 contains', len(df.Variable5.unique()), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['green', 'blue'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check labels in location variable\n",
    "\n",
    "df.Variable5.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue     377\n",
       "green    223\n",
       "Name: Variable5, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency distribution of values in Location variable\n",
    "\n",
    "df.Variable5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green\n",
       "0     0      1\n",
       "1     0      1\n",
       "2     0      1\n",
       "3     0      1\n",
       "4     1      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do One Hot Encoding of Variable5 variable\n",
    "# get k-1 dummy variables after One Hot Encoding \n",
    "# preview the dataset with head() method\n",
    "\n",
    "pd.get_dummies(df.Variable5, drop_first=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['Variable5'] = le.fit_transform(df['Variable5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Variable8'] = le.fit_transform(df['Variable8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 10 columns):\n",
      "TargetVariable    600 non-null int64\n",
      "Variable1         600 non-null float64\n",
      "Variable2         600 non-null float64\n",
      "Variable3         600 non-null int64\n",
      "Variable4         591 non-null float64\n",
      "Variable5         600 non-null int32\n",
      "Variable6         600 non-null float64\n",
      "Variable7         600 non-null int64\n",
      "Variable8         600 non-null int32\n",
      "Variable9         600 non-null int64\n",
      "dtypes: float64(4), int32(2), int64(4)\n",
      "memory usage: 42.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now all the varible are processed and converted to numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 numerical variables\n",
      "\n",
      "The numerical variables are : ['TargetVariable', 'Variable1', 'Variable2', 'Variable3', 'Variable4', 'Variable5', 'Variable6', 'Variable7', 'Variable8', 'Variable9']\n"
     ]
    }
   ],
   "source": [
    "# find numerical variables\n",
    "\n",
    "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
    "\n",
    "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
    "\n",
    "print('The numerical variables are :', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TargetVariable</th>\n",
       "      <th>Variable1</th>\n",
       "      <th>Variable2</th>\n",
       "      <th>Variable3</th>\n",
       "      <th>Variable4</th>\n",
       "      <th>Variable5</th>\n",
       "      <th>Variable6</th>\n",
       "      <th>Variable7</th>\n",
       "      <th>Variable8</th>\n",
       "      <th>Variable9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.357542</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>1</td>\n",
       "      <td>4.606326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000362</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>1</td>\n",
       "      <td>10.824921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000029</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3</td>\n",
       "      <td>69.55</td>\n",
       "      <td>1</td>\n",
       "      <td>5.861325</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.020183</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.50</td>\n",
       "      <td>1</td>\n",
       "      <td>10.896444</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.952665</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.50</td>\n",
       "      <td>0</td>\n",
       "      <td>9.159679</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TargetVariable  Variable1  Variable2  Variable3  Variable4  Variable5  \\\n",
       "0               1   2.357542       29.0          2      10.50          1   \n",
       "1               1   2.000362       50.0          2      10.50          1   \n",
       "2               0   2.000029       34.0          3      69.55          1   \n",
       "3               1   2.020183       50.0          2      10.50          1   \n",
       "4               0   2.952665       45.0          1      35.50          0   \n",
       "\n",
       "   Variable6  Variable7  Variable8  Variable9  \n",
       "0   4.606326          0          1          0  \n",
       "1  10.824921          0          0          0  \n",
       "2   5.861325          8          1          2  \n",
       "3  10.896444          0          2          0  \n",
       "4   9.159679          0          2          0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the numerical variables\n",
    "\n",
    "df[numerical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore problems within numerical variables\n",
    "Now, I will explore the numerical variables.\n",
    "\n",
    "###### Missing values in numerical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetVariable    0\n",
       "Variable1         0\n",
       "Variable2         0\n",
       "Variable3         0\n",
       "Variable4         9\n",
       "Variable5         0\n",
       "Variable6         0\n",
       "Variable7         0\n",
       "Variable8         0\n",
       "Variable9         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numerical variables\n",
    "\n",
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only varibale4 has missing values which is a small margin, so I will remove them since it is only a small amout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetVariable    0\n",
       "Variable1         0\n",
       "Variable2         0\n",
       "Variable3         0\n",
       "Variable4         0\n",
       "Variable5         0\n",
       "Variable6         0\n",
       "Variable7         0\n",
       "Variable8         0\n",
       "Variable9         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is no missing values anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Outliers in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TargetVariable  Variable1  Variable2  Variable3  Variable4  Variable5  \\\n",
      "count           591.0      591.0      591.0      591.0      591.0      591.0   \n",
      "mean              0.0        2.0       31.0        2.0       32.0        0.0   \n",
      "std               0.0        0.0       13.0        1.0       46.0        0.0   \n",
      "min               0.0        2.0        1.0        1.0        4.0        0.0   \n",
      "25%               0.0        2.0       22.0        2.0        8.0        0.0   \n",
      "50%               0.0        2.0       33.0        3.0       15.0        0.0   \n",
      "75%               1.0        2.0       35.0        3.0       31.0        1.0   \n",
      "max               1.0        3.0       71.0        3.0      512.0        1.0   \n",
      "\n",
      "       Variable6  Variable7  Variable8  Variable9  \n",
      "count      591.0      591.0      591.0      591.0  \n",
      "mean         6.0        1.0        1.0        0.0  \n",
      "std          3.0        1.0        1.0        1.0  \n",
      "min          0.0        0.0        0.0        0.0  \n",
      "25%          3.0        0.0        0.0        0.0  \n",
      "50%          6.0        0.0        1.0        0.0  \n",
      "75%          9.0        1.0        2.0        0.0  \n",
      "max         12.0        8.0        2.0        5.0   2\n"
     ]
    }
   ],
   "source": [
    "# view summary statistics in numerical variables\n",
    "\n",
    "print(round(df[numerical].describe()),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In close inpection variable2, and variable4 contains outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will replace outliers with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "median2 = df.loc[df['Variable2']<35, 'Variable2'].median()\n",
    "df[\"Variable2\"] = df[\"Variable2\"].mask(df[\"Variable2\"] >35, median2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "median4 = df.loc[df['Variable4']<35, 'Variable4'].median()\n",
    "df[\"Variable4\"] = df[\"Variable4\"].mask(df[\"Variable4\"] >31, median4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TargetVariable  Variable1  Variable2  Variable3  Variable4  Variable5  \\\n",
      "count           591.0      591.0      591.0      591.0      591.0      591.0   \n",
      "mean              0.0        2.0       26.0        2.0       13.0        0.0   \n",
      "std               0.0        0.0        8.0        1.0        7.0        0.0   \n",
      "min               0.0        2.0        1.0        1.0        4.0        0.0   \n",
      "25%               0.0        2.0       22.0        2.0        8.0        0.0   \n",
      "50%               0.0        2.0       28.0        3.0       10.0        0.0   \n",
      "75%               1.0        2.0       33.0        3.0       15.0        1.0   \n",
      "max               1.0        3.0       35.0        3.0       31.0        1.0   \n",
      "\n",
      "       Variable6  Variable7  Variable8  Variable9  \n",
      "count      591.0      591.0      591.0      591.0  \n",
      "mean         6.0        1.0        1.0        0.0  \n",
      "std          3.0        1.0        1.0        1.0  \n",
      "min          0.0        0.0        0.0        0.0  \n",
      "25%          3.0        0.0        0.0        0.0  \n",
      "50%          6.0        0.0        1.0        0.0  \n",
      "75%          9.0        1.0        2.0        0.0  \n",
      "max         12.0        8.0        2.0        5.0   2\n"
     ]
    }
   ],
   "source": [
    "print(round(df[numerical].describe()),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['TargetVariable'], axis=1)\n",
    "\n",
    "y = df['TargetVariable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((472, 9), (119, 9))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable1</th>\n",
       "      <th>Variable2</th>\n",
       "      <th>Variable3</th>\n",
       "      <th>Variable4</th>\n",
       "      <th>Variable5</th>\n",
       "      <th>Variable6</th>\n",
       "      <th>Variable7</th>\n",
       "      <th>Variable8</th>\n",
       "      <th>Variable9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.252179</td>\n",
       "      <td>25.939619</td>\n",
       "      <td>2.269068</td>\n",
       "      <td>13.352606</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>5.919039</td>\n",
       "      <td>0.519068</td>\n",
       "      <td>1.004237</td>\n",
       "      <td>0.353814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.291845</td>\n",
       "      <td>7.989029</td>\n",
       "      <td>0.845656</td>\n",
       "      <td>6.818650</td>\n",
       "      <td>0.486235</td>\n",
       "      <td>3.412471</td>\n",
       "      <td>1.070576</td>\n",
       "      <td>0.779231</td>\n",
       "      <td>0.745707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.017481</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.965291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.123703</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.862115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.440011</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.609316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.998510</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.955890</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Variable1   Variable2   Variable3   Variable4   Variable5   Variable6  \\\n",
       "count  472.000000  472.000000  472.000000  472.000000  472.000000  472.000000   \n",
       "mean     2.252179   25.939619    2.269068   13.352606    0.381356    5.919039   \n",
       "std      0.291845    7.989029    0.845656    6.818650    0.486235    3.412471   \n",
       "min      2.000000    0.750000    1.000000    4.010000    0.000000    0.045560   \n",
       "25%      2.017481   22.000000    1.000000    8.050000    0.000000    2.965291   \n",
       "50%      2.123703   28.000000    3.000000   10.500000    0.000000    5.862115   \n",
       "75%      2.440011   33.000000    3.000000   15.500000    1.000000    8.609316   \n",
       "max      2.998510   35.000000    3.000000   31.000000    1.000000   11.955890   \n",
       "\n",
       "        Variable7   Variable8   Variable9  \n",
       "count  472.000000  472.000000  472.000000  \n",
       "mean     0.519068    1.004237    0.353814  \n",
       "std      1.070576    0.779231    0.745707  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    1.000000    0.000000  \n",
       "75%      1.000000    2.000000    0.000000  \n",
       "max      8.000000    2.000000    5.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Variable1</th>\n",
       "      <th>Variable2</th>\n",
       "      <th>Variable3</th>\n",
       "      <th>Variable4</th>\n",
       "      <th>Variable5</th>\n",
       "      <th>Variable6</th>\n",
       "      <th>Variable7</th>\n",
       "      <th>Variable8</th>\n",
       "      <th>Variable9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.252555</td>\n",
       "      <td>0.735463</td>\n",
       "      <td>0.634534</td>\n",
       "      <td>0.346151</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.493142</td>\n",
       "      <td>0.064883</td>\n",
       "      <td>0.502119</td>\n",
       "      <td>0.070763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.292280</td>\n",
       "      <td>0.233256</td>\n",
       "      <td>0.422828</td>\n",
       "      <td>0.252636</td>\n",
       "      <td>0.486235</td>\n",
       "      <td>0.286514</td>\n",
       "      <td>0.133822</td>\n",
       "      <td>0.389615</td>\n",
       "      <td>0.149141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.017507</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.123888</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.440667</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719019</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Variable1   Variable2   Variable3   Variable4   Variable5   Variable6  \\\n",
       "count  472.000000  472.000000  472.000000  472.000000  472.000000  472.000000   \n",
       "mean     0.252555    0.735463    0.634534    0.346151    0.381356    0.493142   \n",
       "std      0.292280    0.233256    0.422828    0.252636    0.486235    0.286514   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.017507    0.620438    0.000000    0.149685    0.000000    0.245143   \n",
       "50%      0.123888    0.795620    1.000000    0.240459    0.000000    0.488362   \n",
       "75%      0.440667    0.941606    1.000000    0.425713    1.000000    0.719019   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        Variable7   Variable8   Variable9  \n",
       "count  472.000000  472.000000  472.000000  \n",
       "mean     0.064883    0.502119    0.070763  \n",
       "std      0.133822    0.389615    0.149141  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.500000    0.000000  \n",
       "75%      0.125000    1.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have X_train dataset ready to be fed into the Logistic Regression classifier. I will do it as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = logreg.predict(X_test)\n",
    "\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict_proba method \n",
    "predict_proba method gives the probabilities for the target variable(0 and 1) in this case, in array form.\n",
    "\n",
    "0 is for probability of spam and 1 is for probability of spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11960153, 0.66362266, 0.23635738, 0.89052816, 0.90335974,\n",
       "       0.8769084 , 0.89766746, 0.83806808, 0.86614989, 0.88135244,\n",
       "       0.18367124, 0.42398905, 0.11244695, 0.09764695, 0.88318447,\n",
       "       0.9068002 , 0.90174695, 0.11804071, 0.79928914, 0.90675786,\n",
       "       0.36422255, 0.89247539, 0.86351678, 0.91255305, 0.41282084,\n",
       "       0.39467441, 0.29763729, 0.77976148, 0.89022451, 0.94506691,\n",
       "       0.83643665, 0.71069251, 0.82734594, 0.32420377, 0.89489743,\n",
       "       0.97482594, 0.79348374, 0.8672537 , 0.91304606, 0.89647754,\n",
       "       0.91688286, 0.84205825, 0.41320823, 0.86026661, 0.34460772,\n",
       "       0.85825352, 0.91657123, 0.40053362, 0.11202815, 0.21199636,\n",
       "       0.91141835, 0.42547442, 0.66822046, 0.80589304, 0.31796433,\n",
       "       0.86567155, 0.91146046, 0.87715883, 0.07463014, 0.66554662,\n",
       "       0.28767668, 0.52305992, 0.68035999, 0.83061481, 0.90086705,\n",
       "       0.0841233 , 0.28667498, 0.91499705, 0.09825079, 0.90640395,\n",
       "       0.8982806 , 0.40133912, 0.04827845, 0.3955091 , 0.25532325,\n",
       "       0.12371294, 0.88309566, 0.28099046, 0.6279412 , 0.89924173,\n",
       "       0.25527823, 0.91516779, 0.27806486, 0.92064253, 0.91572163,\n",
       "       0.67197699, 0.70147816, 0.90435305, 0.86485399, 0.43842433,\n",
       "       0.64676503, 0.75457513, 0.91307463, 0.8081743 , 0.10343146,\n",
       "       0.68556593, 0.3217022 , 0.86373409, 0.81029649, 0.17969073,\n",
       "       0.09923463, 0.35843469, 0.66588119, 0.92575738, 0.87048904,\n",
       "       0.14255548, 0.90352146, 0.80322901, 0.86388783, 0.89611105,\n",
       "       0.36050295, 0.41640362, 0.91776315, 0.89543791, 0.88870692,\n",
       "       0.2864947 , 0.8968775 , 0.66977012, 0.78107618])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of getting output as 0 - not a spam\n",
    "\n",
    "logreg.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88039847, 0.33637734, 0.76364262, 0.10947184, 0.09664026,\n",
       "       0.1230916 , 0.10233254, 0.16193192, 0.13385011, 0.11864756,\n",
       "       0.81632876, 0.57601095, 0.88755305, 0.90235305, 0.11681553,\n",
       "       0.0931998 , 0.09825305, 0.88195929, 0.20071086, 0.09324214,\n",
       "       0.63577745, 0.10752461, 0.13648322, 0.08744695, 0.58717916,\n",
       "       0.60532559, 0.70236271, 0.22023852, 0.10977549, 0.05493309,\n",
       "       0.16356335, 0.28930749, 0.17265406, 0.67579623, 0.10510257,\n",
       "       0.02517406, 0.20651626, 0.1327463 , 0.08695394, 0.10352246,\n",
       "       0.08311714, 0.15794175, 0.58679177, 0.13973339, 0.65539228,\n",
       "       0.14174648, 0.08342877, 0.59946638, 0.88797185, 0.78800364,\n",
       "       0.08858165, 0.57452558, 0.33177954, 0.19410696, 0.68203567,\n",
       "       0.13432845, 0.08853954, 0.12284117, 0.92536986, 0.33445338,\n",
       "       0.71232332, 0.47694008, 0.31964001, 0.16938519, 0.09913295,\n",
       "       0.9158767 , 0.71332502, 0.08500295, 0.90174921, 0.09359605,\n",
       "       0.1017194 , 0.59866088, 0.95172155, 0.6044909 , 0.74467675,\n",
       "       0.87628706, 0.11690434, 0.71900954, 0.3720588 , 0.10075827,\n",
       "       0.74472177, 0.08483221, 0.72193514, 0.07935747, 0.08427837,\n",
       "       0.32802301, 0.29852184, 0.09564695, 0.13514601, 0.56157567,\n",
       "       0.35323497, 0.24542487, 0.08692537, 0.1918257 , 0.89656854,\n",
       "       0.31443407, 0.6782978 , 0.13626591, 0.18970351, 0.82030927,\n",
       "       0.90076537, 0.64156531, 0.33411881, 0.07424262, 0.12951096,\n",
       "       0.85744452, 0.09647854, 0.19677099, 0.13611217, 0.10388895,\n",
       "       0.63949705, 0.58359638, 0.08223685, 0.10456209, 0.11129308,\n",
       "       0.7135053 , 0.1031225 , 0.33022988, 0.21892382])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of getting output as 1 - spam\n",
    "\n",
    "logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.7311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, y_test are the true class labels and y_pred_test are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the train-set and test-set accuracy <br>\n",
    "Now, I will compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = logreg.predict(X_train)\n",
    "\n",
    "y_pred_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.8136\n"
     ]
    }
   ],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8136\n",
      "Test set score: 0.7311\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training-set accuracy score is 0.8136 while the test-set accuracy to be 0.7311. These two values are quite comparable. So, there is no question of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the Logsitic Regression model with C=100\n",
    "\n",
    "# instantiate the model\n",
    "logreg100 = LogisticRegression(C=100, solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "logreg100.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8093\n",
      "Test set score: 0.7311\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg100.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Now, I will investigate, what happens if we use more regularized model than the default value of C=1, by setting C=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the Logsitic Regression model with C=001\n",
    "\n",
    "# instantiate the model\n",
    "logreg001 = LogisticRegression(C=0.01, solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "logreg001.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.7839\n",
      "Test set score: 0.7563\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(logreg001.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we use more regularized model by setting C=0.01, then both the training set accuracy decreases and test set accuracy increases relatiev to the default parameters. It shows that it reduces overfitting our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare model accuracy with null accuracy\n",
    "So, the model accuracy is 0.8093. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the null accuracy. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "So, we should first check the class distribution in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77\n",
       "1    42\n",
       "Name: TargetVariable, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class distribution in test set\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the occurences of most frequent class is 77. So, we can calculate null accuracy by dividing 77 by total number of occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy score: 0.7759\n"
     ]
    }
   ],
   "source": [
    "# check null accuracy score\n",
    "\n",
    "null_accuracy = (22067/(22067+6372))\n",
    "\n",
    "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model accuracy score is 0.8093 but null accuracy score is 0.7759. So, we can conclude that our Logistic Regression model is doing a very good job in predicting the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
    "\n",
    "But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making.\n",
    "\n",
    "We have another tool called Confusion matrix that comes to our rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "* True Positives (TP)  True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "* True Negatives (TN)  True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "* False Positives (FP)  False Positives occur when we predict an observation belongs to a certain class but the observation actually does not belong to that class. This type of error is called Type I error.\n",
    "\n",
    "* False Negatives (FN)  False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called Type II error.\n",
    "\n",
    "These four outcomes are summarized in a confusion matrix given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[61 16]\n",
      " [16 26]]\n",
      "\n",
      "True Positives(TP) =  61\n",
      "\n",
      "True Negatives(TN) =  26\n",
      "\n",
      "False Positives(FP) =  16\n",
      "\n",
      "False Negatives(FN) =  16\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows 61 + 26 = 87 correct predictions and 16 + 16 = 32 incorrect predictions.\n",
    "\n",
    "In this case, we have\n",
    "\n",
    "* True Positives (Actual Positive:1 and Predict Positive:1) - 61\n",
    "* True Negatives (Actual Negative:0 and Predict Negative:0) - 32\n",
    "* False Positives (Actual Negative:0 but Predict Positive:1) - 16 (Type I error)\n",
    "* False Negatives (Actual Positive:1 but Predict Negative:0) - 16 (Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2861f1f4048>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "Classification report is another way to evaluate the classification model performance. It displays the precision, recall, f1 and support scores for the model. I have described these terms in later.\n",
    "\n",
    "We can print a classification report as follows:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        77\n",
      "           1       0.62      0.62      0.62        42\n",
      "\n",
      "    accuracy                           0.73       119\n",
      "   macro avg       0.71      0.71      0.71       119\n",
      "weighted avg       0.73      0.73      0.73       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy : 0.7311\n"
     ]
    }
   ],
   "source": [
    "# print classification accuracy\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error : 0.2689\n"
     ]
    }
   ],
   "source": [
    "# print classification error\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "Precision can be defined as the percentage of correctly predicted positive outcomes out of all the predicted positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true and false positives (TP + FP).\n",
    "\n",
    "So, Precision identifies the proportion of correctly predicted positive outcome. It is more concerned with the positive class than the negative class.\n",
    "\n",
    "Mathematically, precision can be defined as the ratio of TP to (TP + FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7922\n"
     ]
    }
   ],
   "source": [
    "# print precision score\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "Recall can be defined as the percentage of correctly predicted positive outcomes out of all the actual positive outcomes. It can be given as the ratio of true positives (TP) to the sum of true positives and false negatives (TP + FN). Recall is also called Sensitivity.\n",
    "\n",
    "Recall identifies the proportion of correctly predicted actual positives.\n",
    "\n",
    "Mathematically, recall can be given as the ratio of TP to (TP + FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall or Sensitivity : 0.7922\n"
     ]
    }
   ],
   "source": [
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive Rate\n",
    "True Positive Rate is synonymous with Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate : 0.7922\n"
     ]
    }
   ],
   "source": [
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate : 0.3810\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity : 0.6190\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1-score\n",
    "f1-score is the weighted harmonic mean of precision and recall. The best possible f1-score would be 1.0 and the worst would be 0.0. f1-score is the harmonic mean of precision and recall. So, f1-score is always lower than accuracy measures as they embed precision and recall into their computation. The weighted average of f1-score should be used to compare classifier models, not global accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support\n",
    "Support is the actual number of occurrences of the class in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the threshold level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11960153, 0.88039847],\n",
       "       [0.66362266, 0.33637734],\n",
       "       [0.23635738, 0.76364262],\n",
       "       [0.89052816, 0.10947184],\n",
       "       [0.90335974, 0.09664026],\n",
       "       [0.8769084 , 0.1230916 ],\n",
       "       [0.89766746, 0.10233254],\n",
       "       [0.83806808, 0.16193192],\n",
       "       [0.86614989, 0.13385011],\n",
       "       [0.88135244, 0.11864756]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities of two classes- 0 and 1\n",
    "\n",
    "y_pred_prob = logreg.predict_proba(X_test)[0:10]\n",
    "\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* In each row, the numbers sum to 1.\n",
    "* There are 2 columns which correspond to 2 classes - 0 and 1.\n",
    "\n",
    "    * Class 0 - predicted probability that there is no spam.\n",
    "\n",
    "    * Class 1 - predicted probability that there is spam.\n",
    "\n",
    "* Importance of predicted probabilities\n",
    "    * We can rank the observations by probability of spam or no spam.\n",
    "* predict_proba process\n",
    "    * Predicts the probabilities\n",
    "    * Choose the class with the highest probability\n",
    "\n",
    "* Classification threshold level\n",
    "\n",
    "    * There is a classification threshold level of 0.5.\n",
    "\n",
    "    * Class 1 - probability of rain is predicted if probability > 0.5.\n",
    "\n",
    "    * Class 0 - probability of no rain is predicted if probability < 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob of - No spam (0)</th>\n",
       "      <th>Prob of - spam (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119602</td>\n",
       "      <td>0.880398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663623</td>\n",
       "      <td>0.336377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236357</td>\n",
       "      <td>0.763643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.890528</td>\n",
       "      <td>0.109472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.903360</td>\n",
       "      <td>0.096640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.876908</td>\n",
       "      <td>0.123092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.102333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.838068</td>\n",
       "      <td>0.161932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.866150</td>\n",
       "      <td>0.133850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.881352</td>\n",
       "      <td>0.118648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prob of - No spam (0)  Prob of - spam (1)\n",
       "0               0.119602            0.880398\n",
       "1               0.663623            0.336377\n",
       "2               0.236357            0.763643\n",
       "3               0.890528            0.109472\n",
       "4               0.903360            0.096640\n",
       "5               0.876908            0.123092\n",
       "6               0.897667            0.102333\n",
       "7               0.838068            0.161932\n",
       "8               0.866150            0.133850\n",
       "9               0.881352            0.118648"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the probabilities in dataframe\n",
    "\n",
    "y_pred_prob_df = pd.DataFrame(data=y_pred_prob, columns=['Prob of - No spam (0)', 'Prob of - spam (1)'])\n",
    "\n",
    "y_pred_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88039847, 0.33637734, 0.76364262, 0.10947184, 0.09664026,\n",
       "       0.1230916 , 0.10233254, 0.16193192, 0.13385011, 0.11864756])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities for class 1 - Probability of spam\n",
    "\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1 - Probability of rain\n",
    "\n",
    "y_pred1 = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of predicted probabilities\n",
    "\n",
    "\n",
    "# adjust the font size \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "\n",
    "# plot histogram with 10 bins\n",
    "plt.hist(y_pred1, bins = 10)\n",
    "\n",
    "\n",
    "# set the title of predicted probabilities\n",
    "plt.title('Histogram of predicted probabilities of spam mails')\n",
    "\n",
    "\n",
    "# set the x-axis limit\n",
    "plt.xlim(0,1)\n",
    "\n",
    "\n",
    "# set the title\n",
    "plt.xlabel('Predicted probabilities of spam')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* We can see that the above histogram is highly positive skewed.\n",
    "* The first column tell us that there are approximately 37 observations with probability between 0.0 and 0.1.\n",
    "* There are small number of observations with probability > 0.5.\n",
    "* So, these small number of observations predict that there will be spam.\n",
    "* Majority of observations predict that there will be no spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC - AUC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "Another tool to measure the classification model performance visually is ROC Curve. ROC Curve stands for Receiver Operating Characteristic Curve. An ROC Curve is a plot which shows the performance of a classification model at various classification threshold levels.\n",
    "\n",
    "The ROC Curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold levels.\n",
    "\n",
    "True Positive Rate (TPR) is also called Recall. It is defined as the ratio of TP to (TP + FN).\n",
    "\n",
    "False Positive Rate (FPR) is defined as the ratio of FP to (FP + TN).\n",
    "\n",
    "In the ROC Curve, we will focus on the TPR (True Positive Rate) and FPR (False Positive Rate) of a single point. This will give us the general performance of the ROC curve which consists of the TPR and FPR at various threshold levels. So, an ROC Curve plots TPR vs FPR at different classification threshold levels. If we lower the threshold levels, it may result in more items being classified as positve. It will increase both True Positives (TP) and False Positives (FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC Curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.title('ROC curve for RainTomorrow classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve help us to choose a threshold level that balances sensitivity and specificity for a particular context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC\n",
    "ROC AUC stands for Receiver Operating Characteristic - Area Under Curve. It is a technique to compare classifier performance. In this technique, we measure the area under the curve (AUC). A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5.\n",
    "\n",
    "So, ROC AUC is the percentage of the ROC plot that is underneath the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC : 0.7715\n"
     ]
    }
   ],
   "source": [
    "# compute ROC AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROC_AUC = roc_auc_score(y_test, y_pred1)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments\n",
    "ROC AUC is a single number summary of classifier performance. The higher the value, the better the classifier.\n",
    "\n",
    "ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in predicting whether a mail is a spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated ROC AUC : 0.8599\n"
     ]
    }
   ],
   "source": [
    "# calculate cross-validated ROC AUC \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Cross_validated_ROC_AUC = cross_val_score(logreg, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:[0.82105263 0.8        0.81052632 0.79787234 0.80645161]\n"
     ]
    }
   ],
   "source": [
    "# Applying 5-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logreg, X_train, y_train, cv = 5, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the cross-validation accuracy by calculating its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.8072\n"
     ]
    }
   ],
   "source": [
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our, original model score is found to be 0.8093. The average cross-validation score is 0.8072. So, we can conclude that cross-validation does not result in performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization using GridSearch CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'penalty': ['l1', 'l2']}, {'C': [1, 10, 100, 1000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = [{'penalty':['l1','l2']}, \n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logreg,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5,\n",
    "                           verbose=0)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch CV best score : 0.8136\n",
      "\n",
      "\n",
      "Parameters that give the best results : \n",
      "\n",
      " {'C': 10}\n",
      "\n",
      "\n",
      "Estimator that was chosen by the search : \n",
      "\n",
      " LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "# best score achieved during the GridSearchCV\n",
    "print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n",
    "\n",
    "# print parameters that give the best results\n",
    "print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n",
    "\n",
    "# print estimator that was chosen by the GridSearch\n",
    "print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch CV score on test set: 0.7311\n"
     ]
    }
   ],
   "source": [
    "# calculate GridSearch CV score on test set\n",
    "\n",
    "print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comments\n",
    "Our original model test accuracy is 0.7311 while GridSearch CV accuracy is 0.7311.\n",
    "We can see that GridSearch CV doesn't also improve the performance for this particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The logistic regression model accuracy score is 0.8093. So, the model does a very good job in predicting whether or not the email is a spam.\n",
    "\n",
    "* Small number of observations predict that there will be there is spam. Majority of observations predict that the mail is not a spam.\n",
    "\n",
    "* The model shows no signs of overfitting.\n",
    "\n",
    "* Increasing the value of C results in higher test set accuracy and also a slightly increased training set accuracy. So, we can conclude that a more complex model should perform better.\n",
    "\n",
    "* Increasing the threshold level results in increased accuracy.\n",
    "\n",
    "* ROC AUC of our model approaches towards 1. So, we can conclude that our classifier does a good job in predicting whether the mail is a spam or not.\n",
    "\n",
    "* Our original model accuracy score is 0.8093 whereas accuracy score after RFECV is 0.8070. So, we can obtain approximately similar accuracy but with reduced set of features.\n",
    "\n",
    "* In the original model, we have FP = 16 whereas FP1 = 16. So, we get approximately same number of false positives. Also, FN = 16 whereas FN1 = 15. So, we get slighly same false negatives.\n",
    "\n",
    "* Our, original model score is found to be 0.8093. The average cross-validation score is 0.8072. So, we can conclude that cross-validation does not result in performance improvement.\n",
    "\n",
    "* Our original model test accuracy is 0.7311 while GridSearch CV accuracy is 0.7311. We can see that GridSearch CV does not also improve the performance for this particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
